{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate indiv plots \n",
    "for short recordings from equivitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import datetime as dt\n",
    "import math\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import heartpy as hp\n",
    "\n",
    "from scipy.signal import butter,filtfilt\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport qex\n",
    "%aimport eq\n",
    "%aimport respy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_dets = pd.read_csv('./Data/Relay_dets.csv',sep = ',')\n",
    "race_dets['Start time'] = pd.to_datetime('2023-05-13 ' + race_dets['Start time'] + ' +0200')\n",
    "race_dets['End time'] = pd.to_datetime('2023-05-13 ' + race_dets['End time'] + ' +0200')\n",
    "race_dets['Duration'] = (race_dets['End time'] - race_dets['Start time']).dt.total_seconds()\n",
    "\n",
    "dev_dets = race_dets.loc[~race_dets['PartID'].isna(),:].reset_index(drop = True).copy()\n",
    "dev_dets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim to race time data\n",
    "Clean up extra files from qiosk and generate trimmed version of signals during the time interval of interest.\n",
    "\n",
    "This process requires stepping through the participant files one at a time to check on data quality. for example, in this set, one expected participant didn't have a recording during race time. BR606 To be evaluated later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partID = dev_dets.loc[0,'PartID']\n",
    "print(partID)\n",
    "projectName = ''\n",
    "sep = '/'\n",
    "path = './Data/'+ partID\n",
    "df_datafiles = qex.qiosk_rec_check(path,projectName,sep)\n",
    "df_datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_files = df_datafiles.iloc[:-1,:].copy()\n",
    "s_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files\n",
    "discardPath = './Data/waste/'\n",
    "for i,row in s_files.iterrows():\n",
    "    tic = time.time()\n",
    "    dataFile = row['FullLoc']\n",
    "    matched = qex.matched_files(dataFile,path,sep)  # outputs locations of csv and sem files\n",
    "    \n",
    "    for fi in matched:\n",
    "        fileName = fi.split('/')[-1]\n",
    "        if fileName.lower().endswith('csv'):\n",
    "            if not fileName.lower().endswith('Recordings.csv'):\n",
    "                dout_f = discardPath + fileName\n",
    "                shutil.move(fi,dout_f) # move the exported csv files to the discard folder\n",
    "        if fileName.lower().endswith('sem'):\n",
    "            out_f = discardPath + fileName\n",
    "            shutil.move(fi,out_f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath = './Data/Relay/'\n",
    "# Interval to keep \n",
    "t1 = pd.to_datetime('2023-05-13 17:00:00.00+0200')# 17:15:00 + 0100  less 15 minutes\n",
    "t2 = pd.to_datetime('2023-05-13 18:55:00.00+0200') # 18:39:13 + 0100 plus 15 minutes\n",
    "#t2 = t1+pd.to_timedelta(240,'s')\n",
    "[t1,t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partID = dev_dets.loc[8,'PartID']\n",
    "print(partID)\n",
    "projectName = ''\n",
    "sep = '/'\n",
    "path = './Data/'+ partID\n",
    "df_datafiles = qex.qiosk_rec_check(path,projectName,sep)\n",
    "df_datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cutting\n",
    "tic = time.time()\n",
    "dataLoc = df_datafiles.iloc[0,14]\n",
    "matched = qex.matched_files(dataLoc,path,sep) # outputs locations of csv \n",
    "for fi in matched:\n",
    "    if fi.lower().endswith('.csv'):\n",
    "    #if not fi.lower().endswith('.sem'):\n",
    "        fp = fi.split(sep)\n",
    "        fn = fp[-1].split('.')\n",
    "        fn_new = fn[0]+'-trimmed.csv'\n",
    "        print(fn_new)\n",
    "        V = qex.cut_by_time(fi,t1,t2)\n",
    "        print(V.columns)\n",
    "        V.to_csv(projectPath + fn_new)\n",
    "        print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick plot group\n",
    "Generate full interval and race interval plots for a single participant \n",
    "\n",
    "plot \n",
    "1. RR\n",
    "2. Resp\n",
    "3. QoM\n",
    "4. Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath = './Data/Relay/'\n",
    "# Interval to keep \n",
    "t1 = pd.to_datetime('2023-05-13 17:00:00.00+0200')# 17:15:00 + 0100  less 15 minutes\n",
    "t2 = pd.to_datetime('2023-05-13 18:55:00.00+0200') # 18:39:13 + 0100 plus 15 minutes\n",
    "#t2 = t1+pd.to_timedelta(240,'s')\n",
    "[t1,t2]\n",
    "eqfiles = os.listdir(projectPath)\n",
    "eqfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for partID in dev_dets['PartID']:\n",
    "    for f in eqfiles:\n",
    "        if partID in f: \n",
    "            if f.startswith('RR'):\n",
    "                print(f)\n",
    "                sf = 5\n",
    "                fig, (axs) = plt.subplots(1, 1,figsize = [14,3])\n",
    "                ax=axs#[0]\n",
    "                V = pd.read_csv(projectPath + f)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])\n",
    "                V = V.loc[V['Interbeat Interval (MS)']>200,:].reset_index(drop=True)\n",
    "                sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                sig_v = V['Interbeat Interval (MS)']\n",
    "\n",
    "                time_s = np.round(np.linspace(0,sig_t.iloc[-1],int(sf*(sig_t.iloc[-1])),endpoint=False),3)\n",
    "                time_dt = V['DateTime'][0] + pd.to_timedelta(time_s,unit='s')\n",
    "                df_sig = pd.DataFrame(index = time_dt)\n",
    "                ax.scatter(x =V['DateTime'],y=(60000/sig_v),color='r',alpha = 0.2,label='Single Beat')\n",
    "\n",
    "                HR = (60000/sig_v).rolling(10,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'10 bt Median'] = f(time_s)\n",
    "                df_sig['10 bt Median'].plot(ax = ax,label = '10 bt Median')\n",
    "\n",
    "                HR = (60000/sig_v).rolling(60,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'60bMed'] = f(time_s)\n",
    "                df_sig['60bMed'].plot(color = 'k',ax = ax,label = '60 bt Median')\n",
    "\n",
    "                ax.set_yticks([40,60,80,100,120,140,160,180,200,220,240])\n",
    "                ax.set_xticks(race_dets['Start time'])\n",
    "                ax.set_xticklabels(race_dets['Start time'].dt.strftime('%H:%M'))\n",
    "                ax.set_xlim([t1,t2])\n",
    "                ax.set_title(partID)\n",
    "                ax.grid()\n",
    "                plt.show()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for partID in dev_dets['PartID']:\n",
    "    for f in eqfiles:\n",
    "        if partID in f: \n",
    "            if f.startswith('DATA'):\n",
    "                print(f)\n",
    "                sf = 5\n",
    "                fig, (axs) = plt.subplots(1, 1,figsize = [14,3])\n",
    "                ax=axs#[0]\n",
    "                V = pd.read_csv(projectPath + f)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])                \n",
    "                sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                time_dt = V['DateTime'][0] + pd.to_timedelta(sig_t,unit='s')\n",
    "                \n",
    "                df_sig = pd.DataFrame(index = time_dt)\n",
    "                df_sig['Temp'] = V['TEMPERATURE'].values\n",
    "                ax.scatter(x =V['DateTime'],y=V['TEMPERATURE'],color='b',alpha = 0.2)\n",
    "\n",
    "#                 df_sig['Temp'].plot(color = 'k',ax = ax,label = 'Skin Tempurature') # pandas is ludicris\n",
    "                ax.set_ylim([32,39])\n",
    "                \n",
    "                ax.set_xticks(race_dets['Start time'].dt.tz_convert('UCT'))\n",
    "                ax.set_xticklabels(race_dets['Start time'].dt.strftime('%H:%M'))\n",
    "                ax.set_xlim([t1,t2])\n",
    "                ax.set_title(partID)\n",
    "                ax.grid()\n",
    "                plt.show()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf = 25 # hz \n",
    "cutoff = 2 #cutoff = np.array([0.05,1]) \n",
    "nyq = 0.5 * sf \n",
    "order = 2 \n",
    "normal_cutoff = cutoff / nyq\n",
    "b, a = butter(order, normal_cutoff, btype='lowpass', analog=False)\n",
    "\n",
    "Comps = ['Inspiration_Onset', 'Expiration_Onset', 'Inspiration_high',\n",
    "       'Expiration_high','Post_Expiration']\n",
    "windows = {'Inspiration_Onset':0.5, 'Expiration_Onset':0.5, 'Inspiration_high':0.2,\n",
    "       'Expiration_high':0.2,'Post_Expiration':0.2}\n",
    "\n",
    "scale_high=0.5\n",
    "scale_low = 0.3\n",
    "\n",
    "for partID in dev_dets['PartID']:\n",
    "    for f in eqfiles:\n",
    "        if partID in f: \n",
    "            if f.startswith('RESPACC'):\n",
    "                print(f)\n",
    "                sf = 25\n",
    "                fig, (axs) = plt.subplots(1, 1,figsize = [14,3])\n",
    "                ax=axs#[0]\n",
    "                V = pd.read_csv(projectPath + f)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])                \n",
    "                ax.scatter(x =V['DateTime'],y=V['Breathing'],color='k',alpha = 0.2)\n",
    "                ax.set_xticks(race_dets['Start time'].dt.tz_convert('UCT'))\n",
    "                ax.set_xticklabels(race_dets['Start time'].dt.strftime('%H:%M'))\n",
    "                ax.set_xlim([t1,t2])\n",
    "                ax.set_title(partID)\n",
    "                ax.grid()\n",
    "                plt.show()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf = 25 # hz \n",
    "cutoff = 2 #cutoff = np.array([0.05,1]) \n",
    "nyq = 0.5 * sf \n",
    "order = 2 \n",
    "normal_cutoff = cutoff / nyq\n",
    "b, a = butter(order, normal_cutoff, btype='lowpass', analog=False)\n",
    "\n",
    "Comps = ['Inspiration_Onset', 'Expiration_Onset', 'Inspiration_high',\n",
    "       'Expiration_high','Post_Expiration']\n",
    "windows = {'Inspiration_Onset':0.5, 'Expiration_Onset':0.5, 'Inspiration_high':0.2,\n",
    "       'Expiration_high':0.2,'Post_Expiration':0.2}\n",
    "\n",
    "scale_high=0.5\n",
    "scale_low = 0.3\n",
    "\n",
    "for partID in dev_dets['PartID']:\n",
    "    for f in eqfiles:\n",
    "        if partID in f: \n",
    "            if f.startswith('FASTACC'):\n",
    "                print(f)\n",
    "                sf = 25\n",
    "                fig, (axs) = plt.subplots(1, 1,figsize = [14,3])\n",
    "                ax=axs#[0]\n",
    "                V = pd.read_csv(projectPath + f)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime']) \n",
    "                #         df = V.loc[:,[ 'Vert Accelerometer','Lat Accelerometer','Long Accelerometer']]\n",
    "\n",
    "                V['Jerk'] = np.sqrt(np.square(V.loc[:,[ 'Vert Accelerometer','Lat Accelerometer','Long Accelerometer']].diff()).sum(axis=1))\n",
    "                ax.scatter(x =V['DateTime'],y=V['Jerk'],color='c',alpha = 0.2)\n",
    "                ax.set_xticks(race_dets['Start time'].dt.tz_convert('UCT'))\n",
    "                ax.set_xticklabels(race_dets['Start time'].dt.strftime('%H:%M'))\n",
    "                ax.set_ylim([0,6000])\n",
    "                ax.set_xlim([t1,t2])\n",
    "                ax.set_title(partID)\n",
    "                ax.grid()\n",
    "                plt.show()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary list of plots, full race\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_times = list(race_dets['Start time'])\n",
    "race_times.append(race_dets['End time'][14])\n",
    "race_times =pd.Series(data=race_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydpi = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dev_dets)):\n",
    "    partID = dev_dets.loc[i,'PartID'] \n",
    "    fig, (axs) = plt.subplots(4, 1,sharex = True, figsize=(10,7), dpi=mydpi) # 14 10\n",
    "    for file in eqfiles:\n",
    "        if partID in file: \n",
    "            if file.startswith('RR'):\n",
    "                sf = 5\n",
    "                ax=axs[0]\n",
    "                V = pd.read_csv(projectPath + file)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])\n",
    "                V = V.loc[V['Interbeat Interval (MS)']>200,:].reset_index(drop=True)\n",
    "                sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                sig_v = V['Interbeat Interval (MS)']\n",
    "                ax.scatter(x =V['DateTime'],y=(60000/V['Interbeat Interval (MS)']),s=10, color='r',alpha = 0.2,label='Single Beat')\n",
    "\n",
    "                time_s = np.round(np.linspace(0,sig_t.iloc[-1],int(sf*(sig_t.iloc[-1])),endpoint=False),3)\n",
    "                time_dt = V['DateTime'][0] + pd.to_timedelta(time_s,unit='s')\n",
    "                df_sig = pd.DataFrame(index = time_dt)\n",
    "                HR = (60000/sig_v).rolling(10,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'10 bt Median'] = f(time_s)\n",
    "                HR = (60000/sig_v).rolling(60,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'60bMed'] = f(time_s)\n",
    "                df_sig['10 bt Median'].plot(ax = ax,label = '10 beat Median')\n",
    "                df_sig['60bMed'].plot(color = 'k',ax = ax,label = '60 beat Median')\n",
    "\n",
    "                ax.set_yticks([40,60,80,100,120,140,160,180,200,220,240])\n",
    "                ax.set_yticklabels(['40','','80','','120','','160','','200','','240'])\n",
    "                ax.set_ylim([40,240])\n",
    "                ax.set_ylabel('Heart BPM')\n",
    "                ax.legend(fontsize = 8)\n",
    "                ax.grid()\n",
    "            if file.startswith('RESPACC'):\n",
    "                sf = 25\n",
    "                ax=axs[1]\n",
    "                V = pd.read_csv(projectPath + file)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])                \n",
    "                ax.scatter(x =V['DateTime'],y=V['Breathing'],s=5,color='k',alpha = 0.2)\n",
    "                ax.set_ylabel('Resp Depth')\n",
    "                ax.grid()\n",
    "            if file.startswith('FASTACC'):               \n",
    "                ax=axs[2]\n",
    "                V = pd.read_csv(projectPath +file)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime']) \n",
    "                V['Jerk'] = np.sqrt(np.square(V.loc[:,[ 'Vert Accelerometer','Lat Accelerometer','Long Accelerometer']].diff()).sum(axis=1))\n",
    "                ax.scatter(x =V['DateTime'],y=V['Jerk'],s=3,color='c',alpha = 0.2)\n",
    "                ax.set_ylim([0,6000])\n",
    "                ax.set_ylabel('QoM (jerk)')\n",
    "                ax.grid()\n",
    "            if file.startswith('DATA'):\n",
    "                ax=axs[3]\n",
    "                V = pd.read_csv(projectPath + file)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])                \n",
    "                ax.scatter(x =V['DateTime'],y=V['TEMPERATURE'],color='b',alpha = 0.2)\n",
    "                ax.set_ylim([32,39])\n",
    "                ax.set_ylabel('Skin Temp C')\n",
    "                ax.grid()\n",
    "            axs[3].set_xticks(race_times)\n",
    "            axs[3].set_xticklabels(race_times.dt.strftime('%H:%M:%S'),fontsize = 8,rotation = 45)\n",
    "            axs[3].set_xlim([t1,t2])\n",
    "            axs[3].set_xlabel('Relay points')\n",
    "            axs[0].set_title(dev_dets.loc[i,'Participant'] + ' Full race time Equivital readings')\n",
    "\n",
    "    plt.savefig('./Plots/Relay/'+ partID+ '_Full_Relay.png',bbox_inches = 'tight',dpi=mydpi)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dets['PartID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "buff = 120 # 2 minutes\n",
    "\n",
    "for i in range(len(dev_dets)):\n",
    "#i = 0\n",
    "    partID = dev_dets.loc[i,'PartID']\n",
    "\n",
    "    ts = dev_dets.loc[i,'Start time']-pd.to_timedelta(buff,unit='s')\n",
    "    te = dev_dets.loc[i,'End time']+pd.to_timedelta(2*buff,unit='s')\n",
    "    print([ts,te])\n",
    "    fig, (axs) = plt.subplots(4, 1,sharex = True, figsize=(12,10), dpi=mydpi)\n",
    "    #fig, (axs) = plt.subplots(4, 1,sharex = True, figsize = [12,10])\n",
    "\n",
    "    for file in eqfiles:\n",
    "        if partID in file: \n",
    "            if file.startswith('RR'):\n",
    "                sf = 5\n",
    "                ax=axs[0]\n",
    "                V = qex.cut_by_time(projectPath + file,ts,te)\n",
    "    #             V = pd.read_csv(projectPath + file)\n",
    "                V['DateTime'] = V.index #pd.to_datetime(V.Index)\n",
    "                V = V.loc[V['Interbeat Interval (MS)']>200,:].reset_index(drop=True)\n",
    "                sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                sig_v = V['Interbeat Interval (MS)']\n",
    "                ax.scatter(x =V['DateTime'],y=(60000/V['Interbeat Interval (MS)']),s=10,color='r',alpha = 0.2,label='Single Beat')\n",
    "\n",
    "                time_s = np.round(np.linspace(0,sig_t.iloc[-1],int(sf*(sig_t.iloc[-1])),endpoint=False),3)\n",
    "                time_dt = V['DateTime'][0] + pd.to_timedelta(time_s,unit='s')\n",
    "                df_sig = pd.DataFrame(index = time_dt)\n",
    "                HR = (60000/sig_v).rolling(10,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'10 bt Median'] = f(time_s)\n",
    "                HR = (60000/sig_v).rolling(60,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'60bMed'] = f(time_s)\n",
    "                df_sig['10 bt Median'].plot(ax = ax,label = '10 bt Median')\n",
    "                df_sig['60bMed'].plot(color = 'k',ax = ax,label = '60 bt Median')\n",
    "\n",
    "                ax.set_yticks([40,60,80,100,120,140,160,180,200,220,240])\n",
    "                ax.set_ylim([40,240])\n",
    "                ax.set_ylabel('Heart BPM')\n",
    "                ax.legend()\n",
    "                ax.grid()\n",
    "            if file.startswith('RESPACC'):\n",
    "                sf = 25\n",
    "                ax=axs[1]\n",
    "                V = qex.cut_by_time(projectPath + file,ts,te) #V = pd.read_csv(projectPath + file)\n",
    "                V['Breathing'].plot(color='k',ax=ax)\n",
    "                ax.set_ylabel('Resp Depth')\n",
    "                ax.grid()\n",
    "            if file.startswith('FASTACC'):               \n",
    "                ax=axs[2]\n",
    "                V = qex.cut_by_time(projectPath + file,ts,te) #V = pd.read_csv(projectPath +file)\n",
    "                V['Jerk'] = np.sqrt(np.square(V.loc[:,[ 'Vert Accelerometer','Lat Accelerometer','Long Accelerometer']].diff()).sum(axis=1))\n",
    "                V['Jerk'].plot(color='c',ax=ax)\n",
    "                ax.set_ylim([0,6000])\n",
    "                ax.set_ylabel('QoM (jerk)')\n",
    "                ax.grid()\n",
    "            if file.startswith('DATA'):\n",
    "                ax=axs[3]\n",
    "                V = qex.cut_by_time(projectPath + file,ts,te) #V = pd.read_csv(projectPath + file)\n",
    "                V['DateTime'] = V.index #pd.to_datetime(V.Index)                \n",
    "                ax.scatter(x =V['DateTime'],y=V['TEMPERATURE'],color='b',alpha = 0.2)\n",
    "                ax.set_ylim([32,39])\n",
    "                ax.set_ylabel('Skin Temp C')\n",
    "                ax.grid()\n",
    "            axs[3].set_xticks(race_times)\n",
    "            axs[3].set_xticklabels(race_times.dt.strftime('%H:%M:%S'),rotation = 10)\n",
    "            axs[3].set_xlim([ts,te])\n",
    "            axs[3].set_xlabel('Relay points')\n",
    "            axs[0].set_title(' '.join([dev_dets.loc[i,'Participant'],'Ettape',str(dev_dets.loc[i,'Leg']),dev_dets.loc[i,'Point'], 'Equivital readings']))\n",
    "\n",
    "    plt.savefig('./Plots/Relay/'+ partID+ '_leg_Relay.png',bbox_inches = 'tight',dpi=mydpi)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre, mid, post\n",
    "excerpt 30 s pre, mid run and post run to contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buff = 5 # 2 minutes\n",
    "\n",
    "for i in range(len(dev_dets)):\n",
    "#     i = 0\n",
    "    partID = dev_dets.loc[i,'PartID']\n",
    "    seg_ts = []\n",
    "    seg_ts.append(dev_dets.loc[i,'Start time']-pd.to_timedelta(120,unit='s'))\n",
    "    seg_ts.append(dev_dets.loc[i,'Start time'] + 0.5*(dev_dets.loc[i,'End time']-dev_dets.loc[i,'Start time'])-pd.to_timedelta(10,unit='s'))\n",
    "    seg_ts.append(dev_dets.loc[i,'End time']+pd.to_timedelta(120,unit='s'))\n",
    "    seg_i = 0\n",
    "    ts = seg_ts[seg_i]\n",
    "    te = seg_ts[seg_i]+pd.to_timedelta(buff,unit='s')\n",
    "    print([ts,te])\n",
    "\n",
    "    fig, (axs) = plt.subplots(4, 1,sharex = True, figsize=(12,10), dpi=mydpi)\n",
    "    #fig, (axs) = plt.subplots(4, 3, figsize = [12,10])\n",
    "\n",
    "    for file in eqfiles:\n",
    "        if partID in file: \n",
    "            if file.startswith('RR'):\n",
    "                for seg_i in range(len(seg_ts)):\n",
    "                    ts = seg_ts[seg_i]\n",
    "                    te = seg_ts[seg_i]+pd.to_timedelta(buff,unit='s')\n",
    "                    sf = 5\n",
    "                    ax=axs[0,seg_i]\n",
    "                    V = qex.cut_by_time(projectPath + file,ts,te)\n",
    "        #             V = pd.read_csv(projectPath + file)\n",
    "                    V['DateTime'] = V.index #pd.to_datetime(V.Index)\n",
    "                    V = V.loc[V['Interbeat Interval (MS)']>200,:].reset_index(drop=True)\n",
    "                    sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                    sig_v = V['Interbeat Interval (MS)']\n",
    "                    ax.scatter(x =V['DateTime'],y=(60000/V['Interbeat Interval (MS)']),s=10,color='r',alpha = 0.2,label='Single Beat')\n",
    "\n",
    "                    time_s = np.round(np.linspace(0,sig_t.iloc[-1],int(sf*(sig_t.iloc[-1])),endpoint=False),3)\n",
    "                    time_dt = V['DateTime'][0] + pd.to_timedelta(time_s,unit='s')\n",
    "                    df_sig = pd.DataFrame(index = time_dt)\n",
    "                    HR = (60000/sig_v).rolling(10,center=True).median() # really lazy smoothing\n",
    "                    f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                    df_sig.loc[:,'10 bt Median'] = f(time_s)\n",
    "                    HR = (60000/sig_v).rolling(60,center=True).median() # really lazy smoothing\n",
    "                    f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                    df_sig.loc[:,'60bMed'] = f(time_s)\n",
    "                    df_sig['10 bt Median'].plot(ax = ax,label = '10 bt Median')\n",
    "                    df_sig['60bMed'].plot(color = 'k',ax = ax,label = '60 bt Median')\n",
    "                    \n",
    "                    ax.set_yticks([40,60,80,100,120,140,160,180,200,220,240])\n",
    "                    ax.set_ylim([40,240])\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_xlim([ts,te])\n",
    "                    ax.grid()\n",
    "                axs[0,0].set_ylabel('Heart BPM')\n",
    "            if file.startswith('RESPACC'):\n",
    "                for seg_i in range(len(seg_ts)):\n",
    "                    ts = seg_ts[seg_i]\n",
    "                    te = seg_ts[seg_i]+pd.to_timedelta(buff,unit='s')\n",
    "                    ax=axs[1,seg_i]\n",
    "                    V = qex.cut_by_time(projectPath + file,ts,te) #V = pd.read_csv(projectPath + file)\n",
    "                    V['Breathing'].plot(color='k',ax=ax)\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_xlim([ts,te])\n",
    "                    ax.grid()\n",
    "                axs[1,0].set_ylabel('Resp Depth')\n",
    "            if file.startswith('FASTACC'):               \n",
    "                for seg_i in range(len(seg_ts)):\n",
    "                    ts = seg_ts[seg_i]\n",
    "                    te = seg_ts[seg_i]+pd.to_timedelta(buff,unit='s')\n",
    "                    ax=axs[2,seg_i]\n",
    "                    V = qex.cut_by_time(projectPath + file,ts,te) #V = pd.read_csv(projectPath +file)\n",
    "                    V['Jerk'] = np.sqrt(np.square(V.loc[:,[ 'Vert Accelerometer','Lat Accelerometer','Long Accelerometer']].diff()).sum(axis=1))\n",
    "                    V['Jerk'].plot(color='c',ax=ax)\n",
    "#                     ax.set_ylim([0,6000])\n",
    "                    ax.set_xlim([ts,te])\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.grid()\n",
    "                axs[2,0].set_ylabel('QoM (jerk)')\n",
    "            if file.startswith('ECG'):\n",
    "                for seg_i in range(len(seg_ts)):\n",
    "                    ts = seg_ts[seg_i]\n",
    "                    te = seg_ts[seg_i]+pd.to_timedelta(buff,unit='s')\n",
    "                    ax=axs[3,seg_i]\n",
    "                    V = qex.cut_by_time(projectPath + file,ts,te) #V = pd.read_csv(projectPath + file)\n",
    "                    V['DateTime'] = V.index #pd.to_datetime(V.Index)      \n",
    "                    V['Lead 1'].plot(color='b',ax=ax)\n",
    "                    ax.set_xlim([ts,te])\n",
    "                    ax.grid()\n",
    "                    ax.set_ylim([-2,2])\n",
    "                axs[3,0].set_ylabel('ECG')\n",
    "    axs[0,1].set_title(' '.join([dev_dets.loc[i,'Participant'],str(buff),'s samples','Equivital readings']))\n",
    "    axs[3,0].set_xlabel('Pre-Run (from -120s)')\n",
    "    axs[3,1].set_xlabel('Mid-Run')\n",
    "    axs[3,2].set_xlabel('Post-Run (from +120s)')\n",
    "    plt.savefig('./Plots/Relay/'+ partID+ '_5s_samples_Relay.png',bbox_inches = 'tight',dpi=mydpi)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary resp style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath = './Data/Relay/'\n",
    "# Interval to keep \n",
    "t1 = pd.to_datetime('2023-05-13 17:00:00.00+0200').tz_convert('UTC')# 17:15:00 + 0100  less 15 minutes\n",
    "t2 = pd.to_datetime('2023-05-13 18:55:00.00+0200').tz_convert('UTC') # 18:39:13 + 0100 plus 15 minutes\n",
    "#t2 = t1+pd.to_timedelta(240,'s')\n",
    "[t1,t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# phase plots only worth looking at much more closely. \n",
    "# tryin again when cutting to leg\n",
    "\n",
    "sf = 25 # hz \n",
    "cutoff = 2 #cutoff = np.array([0.05,1]) \n",
    "nyq = 0.5 * sf \n",
    "order = 2 \n",
    "normal_cutoff = cutoff / nyq\n",
    "b, a = butter(order, normal_cutoff, btype='lowpass', analog=False)\n",
    "\n",
    "# Comps = ['Inspiration_Onset', 'Expiration_Onset', 'Inspiration_high',\n",
    "#        'Expiration_high','Post_Expiration']\n",
    "# windows = {'Inspiration_Onset':0.5, 'Expiration_Onset':0.5, 'Inspiration_high':0.2,\n",
    "#        'Expiration_high':0.2,'Post_Expiration':0.2}\n",
    "\n",
    "insp_t_bin = np.linspace(0,3,int(1.5*sf)+1,endpoint=True)\n",
    "depth_bin = np.linspace(0,1000,int(1.5*sf)+1,endpoint=True)\n",
    "scale_high=0.5\n",
    "scale_low = 0.3\n",
    "for i in range(len(dev_dets)):\n",
    "    partID = dev_dets.loc[i,'PartID']\n",
    "    buff = 10\n",
    "    ts = (dev_dets.loc[i,'Start time']-pd.to_timedelta(buff,unit='s')).tz_convert('UTC')\n",
    "    te = (dev_dets.loc[i,'End time']+pd.to_timedelta(buff,unit='s')).tz_convert('UTC')\n",
    "    print([ts,te])\n",
    "\n",
    "    for file in eqfiles:\n",
    "        if partID in  file: \n",
    "            if file.startswith('RESPACC'):\n",
    "                print(file)\n",
    "                V = qex.cut_by_time(projectPath + file,t1,t2)\n",
    "                t1 = V.index[0]\n",
    "                V['DateTime'] = V.index \n",
    "                sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                sig_v = V['Breathing']\n",
    "                f = interpolate.interp1d(sig_t, sig_v,fill_value='extrapolate')\n",
    "\n",
    "                dur = sig_t.max()\n",
    "                time_s = np.round(np.linspace(0,dur,int(sf*(dur)),endpoint=False),3)\n",
    "                df_sig = pd.DataFrame(index = time_s)\n",
    "                df_sig['Resp'] = filtfilt(b, a, f(time_s))\n",
    "\n",
    "                Breaths = respy.Breath_Features(df_sig['Resp'],filtered=True)  \n",
    "\n",
    "                fig, axs = plt.subplots(2, 3,figsize = [12,6])\n",
    "\n",
    "                Q_Breaths = Breaths.loc[Breaths['In']<(ts-t1).total_seconds(),:]\n",
    "                Q_Breaths = Q_Breaths.loc[Q_Breaths['In']>((ts-t1).total_seconds()-600),:]\n",
    "                ax = axs[0,0]\n",
    "                counts, xedges, yedges, im = ax.hist2d(Q_Breaths.Insp_T,Q_Breaths.Depth, bins=(insp_t_bin,depth_bin), cmap=plt.cm.jet)\n",
    "                fig.colorbar(im, ax=ax)\n",
    "                ax.set_title('Pre run (10 minutes)')\n",
    "                ax.set_xlabel('Inspiration Time (s)')\n",
    "                ax.set_ylabel('Depth') \n",
    "                ax = axs[1,0]\n",
    "                counts, xedges, yedges, im = ax.hist2d(Q_Breaths.Exp_T,Q_Breaths.Depth, bins=(insp_t_bin,depth_bin), cmap=plt.cm.jet)\n",
    "                fig.colorbar(im, ax=ax)\n",
    "                ax.set_xlabel('Expiration Time (s)')\n",
    "                ax.set_ylabel('Depth') \n",
    "\n",
    "\n",
    "                Q_Breaths = Breaths.loc[Breaths['In']<(te-t1).total_seconds(),:]\n",
    "                Q_Breaths = Q_Breaths.loc[Q_Breaths['In']>(ts-t1).total_seconds(),:]\n",
    "                ax = axs[0,1]\n",
    "                counts, xedges, yedges, im = ax.hist2d(Q_Breaths.Insp_T,Q_Breaths.Depth, bins=(insp_t_bin,depth_bin), cmap=plt.cm.jet)\n",
    "                fig.colorbar(im, ax=ax)\n",
    "                ax.set_title('During run ' + partID)\n",
    "                ax.set_xlabel('Inspiration Time (s)')\n",
    "                ax = axs[1,1]\n",
    "                counts, xedges, yedges, im = ax.hist2d(Q_Breaths.Exp_T,Q_Breaths.Depth, bins=(insp_t_bin,depth_bin), cmap=plt.cm.jet)\n",
    "                fig.colorbar(im, ax=ax)\n",
    "                ax.set_xlabel('Expiration Time (s)')\n",
    "\n",
    "                ax = axs[0,2]\n",
    "                Q_Breaths = Breaths.loc[Breaths['In']>(te-t1).total_seconds(),:]\n",
    "                Q_Breaths = Q_Breaths.loc[Q_Breaths['In']<((te-t1).total_seconds()+600),:]\n",
    "                counts, xedges, yedges, im = ax.hist2d(Q_Breaths.Insp_T,Q_Breaths.Depth, bins=(insp_t_bin,depth_bin), cmap=plt.cm.jet)\n",
    "                fig.colorbar(im, ax=ax)\n",
    "                ax.set_title('Post run (10 minutes)')\n",
    "                ax.set_xlabel('Inspiration Time (s)')\n",
    "                ax = axs[1,2]\n",
    "                counts, xedges, yedges, im = ax.hist2d(Q_Breaths.Exp_T,Q_Breaths.Depth, bins=(insp_t_bin,depth_bin), cmap=plt.cm.jet)\n",
    "                fig.colorbar(im, ax=ax)\n",
    "                ax.set_xlabel('Expiration Time (s)')\n",
    "\n",
    "    plt.savefig('./Plots/Relay/'+ partID+ '_resp_phases.png',dpi = 300)\n",
    "\n",
    "    plt.show()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sf = 5\n",
    "fig, (axs) = plt.subplots(1, 1,figsize = [14,5])\n",
    "ax=axs#[0]\n",
    "\n",
    "for i in range(len(dev_dets)):\n",
    "    partID = dev_dets.loc[i,'PartID']\n",
    "    for f in eqfiles:\n",
    "        if partID in f: \n",
    "            if f.startswith('RR'):\n",
    "                print(f)\n",
    "\n",
    "                V = pd.read_csv(projectPath + f)\n",
    "                V['DateTime'] = pd.to_datetime(V['DateTime'])\n",
    "                V = V.loc[V['Interbeat Interval (MS)']>200,:].reset_index(drop=True)\n",
    "                sig_t = (V['DateTime']-V['DateTime'][0]).dt.total_seconds()\n",
    "                sig_v = V['Interbeat Interval (MS)']\n",
    "\n",
    "                time_s = np.round(np.linspace(0,sig_t.iloc[-1],int(sf*(sig_t.iloc[-1])),endpoint=False),3)\n",
    "                time_dt = V['DateTime'][0] + pd.to_timedelta(time_s,unit='s')\n",
    "                df_sig = pd.DataFrame(index = time_dt)\n",
    "\n",
    "                HR = (60000/sig_v).rolling(60,center=True).median() # really lazy smoothing\n",
    "                f = interpolate.interp1d(sig_t, HR,fill_value='extrapolate')\n",
    "                df_sig.loc[:,'60bMed'] = f(time_s)\n",
    "                df_sig['60bMed'].plot(ax = ax,label = dev_dets.loc[i,'Participant'])\n",
    "\n",
    "ax.set_yticks([40,60,80,100,120,140,160,180,200,220,240])\n",
    "ax.set_xticks(race_dets['Start time'])\n",
    "ax.set_xticklabels(race_dets['Start time'].dt.strftime('%H:%M'))\n",
    "ax.set_xlim([t1,t2])\n",
    "ax.set_ylabel('BPM (60 bts)')\n",
    "ax.set_title('All participants, BPM')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V['DateTime']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
